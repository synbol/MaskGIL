# Exploring the Design Space of Autoregressive Models for Efficient and Scalable Image Generation


## Repository Structure
Here's an overview of the repository structure:

      â”œ MaskGIL/
      |    â”œâ”€â”€ Metrics/                               <- evaluation tool
      |    |      â”œâ”€â”€ inception_metrics.py                  
      |    |      â””â”€â”€ sample_and_eval.py
      |    |    
      |    â”œâ”€â”€ Network/                             
      |    |      â”œâ”€â”€ Taming/                         <- VQGAN architecture   
      |    |      â”œâ”€â”€ tokenizer/                      <- VQGAN architecture  
      |    |      â”œâ”€â”€ gpt.py                          <- Bi-Direction LLaMA architecture      
      |    |      â””â”€â”€ transformer.py                  <- Bi-Transformer architecture  
      |    |
      |    â”œâ”€â”€ Trainer/                               <- Main class for training
      |    |      â”œâ”€â”€ trainer.py                      <- Abstract trainer     
      |    |      â””â”€â”€ vit.py                          <- Trainer of MaskGIL
      |    â”œâ”€â”€ images/                                <- Image samples         
      |    |
      |    â”œâ”€â”€ requirements.yaml                      <- help to install env 
      |    â”œâ”€â”€ FID_sample.py                          <- sample 50K images for FID
      |    â””â”€â”€ main.py                                <- Main
      

## ðŸ”¥ Update
[2024.10.07] Code and c2i checkpoints are released !

## ðŸŒ¿ Introduction


## ðŸ¦„ Class-conditional image generation on ImageNet

Method | params| tokens | FID (256x256) | weight 
--- |:---:|:---:|:---:|:---:|
MaskGIL-B   | 111M | 16x16 | 5.46 | [c2i_B_256.pt]()
MaskGIL-L   | 343M | 16x16 | 3.80 | [c2i_L_256.pt]()
MaskGIL-XL  | 775M | 24x24 | 2.62 | [c2i_X_256.pt]()
MaskGIL-XXL | 1.4B | 24x24 | 2.34 | [c2i_XXL_256.pt]()
